using Pkg
Pkg.add("DataStructures")
Pkg.add("Distributions")

#HÃ m phá»¥ trá»£ tÃ¬m argmax láº¥y tá»« tÃ i liá»‡u tr.662
function Base.findmax(f::Function, xs)
    f_max = -Inf
    x_max = first(xs)
    for x in xs
        v = f(x)
        if v > f_max
            f_max, x_max = v, x
        end
    end
    return f_max, x_max
end

Base.argmax(f::Function, xs) = findmax(f, xs)[2]
using DataStructures




#Táº­p ngÆ°á»i chÆ¡i
struct Agent
    a::Vector{Int64}

    function Agent()
        x=[1,2]
        new(x)
    end
end

#Táº­p hÃ nh Ä‘á»™ng cÃ³ thá»ƒ thá»±c hiá»‡n
struct JointActionSpace
    actionSpaces::Vector{Int64}

    function JointActionSpace()
        x=[]
        for i=2:98
            push!(x,i)
        end
        new(x)
    end
end

#Äá»™ tá»‘i Æ°u cá»§a hÃ nh Ä‘á»™ng
struct DiscountFactor
    y::Float64

    function DiscountFactor()
        new(0.5)
    end
end

#Struct game travelerDilemma
struct TravelerDilemma
    Î³::DiscountFactor# discount factor
    â„::Agent # agents
    ğ’œ::JointActionSpace# joint action space
function TravelerDilemma()
    new(DiscountFactor(),Agent(),JointActionSpace())
end

end

#ChÃ­nh sÃ¡ch cá»§a ngÆ°á»i chÆ¡i 
struct SimpleGamePolicy
    p # dictionary mapping actions to probabilities
    function SimpleGamePolicy(p::Base.Generator)
        return SimpleGamePolicy(Dict(p))
    end
    function SimpleGamePolicy(p::Dict)
        vs = collect(values(p))
        vs ./= sum(vs)
        return new(Dict(k => v for (k,v) in zip(keys(p), vs)))
    end
    SimpleGamePolicy(ai) = new(Dict(ai => 1.0))
end


#Tinh reward cá»§a 2 hÃ nh Ä‘á»™ng
function resultFunction(a::Tuple{Int64, Int64})
    if a[1]==a[2]
        return [a[1],a[2]]
    elseif a[1]<a[2]
        return [a[1]+2,a[1]-2]
    elseif a[1]>a[2]
        return [a[2]-2,a[2]+2]
    end
end

#Tinh probability
(Ï€i::SimpleGamePolicy)(ai) = get(Ï€i.p, ai, 0.0)
#Tao táº­p hÃ nh Ä‘á»™ng cÃ³ thá»ƒ xáº£y ra. VD: nháº­n ([1,2]) tráº£ vá» ([1,1],[1,2],[2,1],[2,2])
joint(X1::Vector{Int64}, X2::Vector{Int64}) = vec(collect(Iterators.product(X1,X2)))

#TÃ­nh utility
function utility(m::TravelerDilemma, Ï€, i)
    actSpace = m.ğ’œ.actionSpaces
    p(a) = prod(Ï€i(ai) for (Ï€i,ai) in zip(Ï€,a))
    return sum(resultFunction(a)[i]*p(a) for a in joint(actSpace,actSpace))
end

#GhÃ©p chÃ­nh sÃ¡ch má»›i
joint(Ï€, Ï€i, i) = [i == j ? Ï€i : Ï€j for (j, Ï€j) in enumerate(Ï€)]

#Tráº£ vá» cÃ¢u tráº£ lá»i tá»‘t nháº¥t
function best_response(ğ’«::TravelerDilemma, Ï€, i)
    U(ai) = utility(ğ’«, joint(Ï€, SimpleGamePolicy(ai), i), i)
    ai = argmax(U, ğ’«.ğ’œ.actionSpaces)
    return SimpleGamePolicy(ai)
end

#TÃ­nh nash theo phÆ°Æ¡ng phÃ¡p vÃ²ng láº·p best response
struct IteratedBestResponse
    k_max # number of iterations
    Ï€ # initial policy
end

function IteratedBestResponse(ğ’«::TravelerDilemma, k_max)
    Ï€ = [SimpleGamePolicy(ai => 1.0 for ai in ğ’œi) for ğ’œi in ğ’«.ğ’œ.actionSpaces]
    return IteratedBestResponse(k_max, Ï€)
end

function solve(M::IteratedBestResponse, ğ’«::TravelerDilemma)
    Ï€ = M.Ï€
    for k in 1:M.k_max
        Ï€ = [best_response(ğ’«, Ï€, i) for i in ğ’«.â„.a]
    end
    return Ï€
end

p=TravelerDilemma()
iterRes=IteratedBestResponse(p,5)
solve(iterRes,p)